{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying Node Capacities\n",
    "\n",
    "Evaluation of solution quality for abilene network with increasing node capacities.\n",
    "\n",
    "## Scenario\n",
    "\n",
    "* Network: Abilene: 11 nodes, 14 edges\n",
    "* All nodes with random cap between (0-2)*(1,2,3,4,5,6,7)\n",
    "* 4 Ingress Nodes\n",
    "* MMPP flow arrival with inter-arr time 8-12\n",
    "* Flow weight = 1, Delay weight = 0\n",
    "\n",
    "## Approaches\n",
    "\n",
    "* BSP: 30 repetition per scenario\n",
    "* Load Balance: 30 repetition per scenario\n",
    "* Shortest Path: 30 repetition per scenario\n",
    "* DRL: \n",
    "  * 100k training  with 10 different seeds on larger networks --> auto select best one\n",
    "  * 30x 1 testing episode with best agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dat/git_folder_edge_4/realVNF/venv/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from operator import itemgetter\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx\n",
    "%matplotlib inline\n",
    "\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "# prefix for saving plot files\n",
    "plot_prefix = 'var-node-cap_mmpp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted version\n",
    "def read_results_over_networks(dir, df=None, rf=None, best_only=False, network_dir=None, skip_rf=True, alg_name=None):\n",
    "    \"\"\"Read result files in the directory and append results to the data frame\"\"\"\n",
    "    if df is None:\n",
    "        df = pd.DataFrame()\n",
    "    if rf is None:\n",
    "        rf = pd.DataFrame()\n",
    "\n",
    "    if network_dir is not None:\n",
    "        dir = f'{network_dir}/{dir}'\n",
    "    \n",
    "    for root, sub_dirs, files in os.walk(dir):\n",
    "        if len(files) > 0 and (not '.ipynb_checkpoints' in root):                \n",
    "            if 'best' in root or not best_only:\n",
    "                # read metrics at end of simulation (last row)\n",
    "                df_metrics = pd.read_csv(f'{root}/metrics.csv')\n",
    "                data = df_metrics.tail(1)\n",
    "                # get the last placement\n",
    "                df_placements = pd.read_csv(f'{root}/placements.csv').groupby('time')\n",
    "                placements = pd.concat(deque(map(itemgetter(1), df_placements), maxlen=1))\n",
    "                \n",
    "                \n",
    "                # add algorithm name, number of ingress nodes, and number of vnfs as columns\n",
    "                with open(f'{root}/input.yaml', 'r') as f:\n",
    "                    inputs = yaml.load(f, Loader=yaml.Loader)\n",
    "                if alg_name is None:\n",
    "                    alg_name = inputs['algorithm']\n",
    "                \n",
    "                # read number of nodes in network\n",
    "                network_file = [filename for filename in files if \".graphml\" in filename]\n",
    "                assert len(network_file) == 1\n",
    "                network_file = network_file[0]\n",
    "                if network_dir is None:\n",
    "                    network_dir = network_file.split('.')[0]\n",
    "                nx_network = networkx.read_graphml(f'{root}/{network_file}')\n",
    "                num_nodes = nx_network.number_of_nodes()\n",
    "                network_cap = sum([n[1].get('NodeCap') for n in nx_network.nodes(data=True)])\n",
    "                \n",
    "                data.insert(loc=0, column='network', value=network_dir)\n",
    "                data.insert(loc=1, column='network_cap', value=network_cap)\n",
    "                data.insert(loc=2, column='algorithm', value=alg_name)\n",
    "                data.insert(loc=3, column='num_nodes', value=num_nodes)\n",
    "                data.insert(loc=4, column='num_ingress', value=inputs['num_ingress'])\n",
    "                data.insert(loc=data.columns.size, column='num_vnfs', value=placements['sf'].size)\n",
    "                \n",
    "                df = df.append(data, ignore_index=True, sort=True)\n",
    "                fix_dtypes(df)\n",
    "                df.sort_values(['algorithm', 'num_nodes'], inplace=True)\n",
    "                df = df[['network', 'algorithm', 'num_nodes', 'num_ingress', 'network_cap', 'total_flows', 'successful_flows', 'dropped_flows', 'in_network_flows', 'avg_end2end_delay', 'num_vnfs']]\n",
    "\n",
    "                if not skip_rf:\n",
    "                    # Reading resource metrics and creating a new Resource Dataframe\n",
    "                    # Getting the last group using the Deque operation\n",
    "                    rf_resources = pd.read_csv(f'{root}/node_metrics.csv').groupby('time')\n",
    "                    resources = pd.concat(deque(map(itemgetter(1), rf_resources), maxlen=1))\n",
    "                    resources.insert(loc=0, column='network', value=network_dir)\n",
    "                    resources.insert(loc=1, column='network_cap', value=network_cap)\n",
    "                    resources.insert(loc=2, column='algorithm', value=inputs['algorithm'])\n",
    "                    resources.insert(loc=3, column='num_nodes', value=num_nodes)\n",
    "                    resources.insert(loc=4, column='num_ingress', value=inputs['num_ingress'])\n",
    "                    rf = rf.append(resources, ignore_index=True, sort=True)\n",
    "                    rf.sort_values(['algorithm', 'num_nodes'], inplace=True)\n",
    "                \n",
    "    #Add percentage of successful flows\n",
    "    succ_percentage = []\n",
    "    for index, row in df.iterrows():\n",
    "        succ_percentage.append(row['successful_flows'] / row['total_flows'] * 100)\n",
    "    df['successful_percentage'] = succ_percentage\n",
    "    return df, rf\n",
    "\n",
    "\n",
    "def fix_dtypes(df):\n",
    "    \"\"\"Set correct dtypes and order\"\"\"\n",
    "    df['avg_end2end_delay'] = pd.to_numeric(df['avg_end2end_delay'])\n",
    "    df['total_flows'] = pd.to_numeric(df['total_flows'])\n",
    "    df['successful_flows'] = pd.to_numeric(df['successful_flows'])\n",
    "    df['dropped_flows'] = pd.to_numeric(df['dropped_flows'])\n",
    "    df['in_network_flows'] = pd.to_numeric(df['in_network_flows'])\n",
    "    \n",
    "    \n",
    "def df_mean_std(df, group_by=['network', 'algorithm', 'num_nodes', 'num_ingress' , 'network_cap']):\n",
    "    \"\"\"Return 2 new dfs with 1) average and 2) std values\"\"\"\n",
    "    df_mean = df.groupby(group_by).mean().reset_index()\n",
    "    df_std = df.groupby(group_by).std().reset_index()\n",
    "    return df_mean, df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-37447b812fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_results_over_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# only select results with 4 ingress nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_ingress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e571a51d60de>\u001b[0m in \u001b[0;36mdf_mean_std\u001b[0;34m(df, group_by)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_nodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_ingress'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'network_cap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;34m\"\"\"Return 2 new dfs with 1) average and 2) std values\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mdf_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mdf_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_folder_edge_4/realVNF/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[1;32m   5805\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5806\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5807\u001b[0;31m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5808\u001b[0m         )\n\u001b[1;32m   5809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_folder_edge_4/realVNF/venv/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_folder_edge_4/realVNF/venv/lib/python3.6/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'network'"
     ]
    }
   ],
   "source": [
    "# read results\n",
    "df = pd.DataFrame()\n",
    "rf = pd.DataFrame()\n",
    "\n",
    "df, rf = read_results_over_networks('drl', df, rf, best_only=True, alg_name='DRL')\n",
    "df, rf = read_results_over_networks('bsp', df, rf, best_only=False, alg_name='BSP')\n",
    "df, rf = read_results_over_networks('bsp-ad', df, rf, best_only=False, alg_name='BSP Ad.')\n",
    "df, rf = read_results_over_networks('sp', df, rf, best_only=False, alg_name='SP')\n",
    "df, rf = read_results_over_networks('lb', df, rf, best_only=False, alg_name='LB')\n",
    "\n",
    "df_mean, df_std = df_mean_std(df)\n",
    "# only select results with 4 ingress nodes\n",
    "df_mean = df_mean[df_mean['num_ingress'] == 4]\n",
    "df_std = df_std[df_std['num_ingress'] == 4]\n",
    "\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successful Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.1, style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_successful_flows(df_mean, df_std, filename=None):\n",
    "    algs=['DRL', 'BSP','BSP Ad.', 'SP', 'LB']\n",
    "    sns.set(font_scale=1, style='white')\n",
    "    markers = ['^', 'v', 's', 'D', '<', '>', 'P', 'X', 'o', '8', 'p']\n",
    "    fig, ax1 = plt.subplots(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.1, style='white')\n",
    "\n",
    "    # plot successful flows\n",
    "    for i, algorithm in enumerate(algs):\n",
    "        alg_df_mean = df_mean[df_mean['algorithm'] == algorithm]\n",
    "        alg_df_std = df_std[df_std['algorithm'] == algorithm]\n",
    "        ax1.errorbar(alg_df_mean['network_cap'], alg_df_mean['successful_percentage'], yerr=alg_df_std['successful_percentage'], capsize=5,\n",
    "                    label='{}'.format(algorithm), marker=markers[i])\n",
    "\n",
    "    # set axis, title, legend\n",
    "    # ax1.set_title('Successful Flows')\n",
    "    ax1.set_xlabel('Total Node Capacity')\n",
    "    ax1.set_ylabel('Successful Flows [%]')\n",
    "    ax1.set_ylim(0, 105)\n",
    "\n",
    "    ax1.tick_params(axis='both', direction='inout', length=5, bottom=True, left=True, right=True, top=True)\n",
    "\n",
    "    # remove error bars from legend: https://stackoverflow.com/a/15551976/2745116\n",
    "    # get handles\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    # remove the errorbars\n",
    "    handles = [h[0] for h in handles]\n",
    "    # use them in the legend\n",
    "    ax1.legend(handles, labels, numpoints=1)\n",
    "\n",
    "    # ax1.legend()\n",
    "    if filename is not None:\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'plots/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_successful_flows(df_mean, df_std)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}